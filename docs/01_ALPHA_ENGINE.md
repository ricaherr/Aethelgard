# AETHELGARD: 01 ALPHA ENGINE

## üéØ Generaci√≥n de Alpha y Estrategias
Motor de escaneo proactivo y generaci√≥n de se√±ales basadas en patrones institucionales.

---

### üß† Componentes Alpha
- **Scanner Proactivo**: Escaneo multi-timeframe de alta eficiencia.
- **Regime Classifier**: Clasificaci√≥n de contexto (Trend, Range, Volatile).
- **Technical Analyzer**: Fuente √∫nica de verdad para indicadores vectorizados.
- **Signal Factory**: Generador de oportunidades con scoring din√°mico.
- **Strategy Jury (The Jury)**: Mecanismo de decisi√≥n que eval√∫a la probabilidad de √©xito basada en el rendimiento reciente (Darwinismo Algor√≠tmico).

---

### üèõÔ∏è Estrategia Universal
El sistema utiliza un **Shadow Engine** que decide si una se√±al merece riesgo real o seguimiento virtual, bas√°ndose en el "Shadow Performance" de la estrategia en el r√©gimen actual.

---

### üìä Estrategias de Ingenier√≠a
- **Oliver Velez Swing v2**: Basada en Velas Elefante y ubicaci√≥n en SMA20.
- **Multi-Timeframe Confluence**: Sistema EDGE para refuerzo de se√±ales por alineaci√≥n de temporalidades.

---

### ‚öôÔ∏è Configuraci√≥n Estrat√©gica
Toda la l√≥gica de Alpha se alimenta de par√°metros din√°micos optimizados por el sistema `EdgeTuner`.

---

### ü§ñ EdgeTuner ‚Äî Feedback Loop Aut√≥nomo
**Archivo**: `core_brain/edge_tuner.py`

El `EdgeTuner` es el cerebro adaptativo del sistema. Ajusta pesos de m√©tricas por r√©gimen (`regime_configs`) y par√°metros t√©cnicos globales bas√°ndose en resultados reales de trading.

**Flujo Delta Feedback**:
1. Trade cierra ‚Üí `TradeClosureListener` detecta el resultado
2. `process_trade_feedback(trade_result, predicted_score, regime)` calcula `Delta = Resultado - Score_Predicho`
3. Si `|Delta|` supera umbrales ‚Üí `_adjust_regime_weights()` ajusta el peso dominante del r√©gimen
4. El resultado se persiste en `edge_learning` con `action_taken` descriptivo

**M√©todos clave**:
| M√©todo | Prop√≥sito |
|---|---|
| `process_trade_feedback()` | Entry point del feedback loop |
| `apply_governance_limits()` | Safety Governor: aplica floor/ceiling/smoothing |
| `_adjust_regime_weights()` | Ajusta pesos en DB con governance integrado |
| `adjust_parameters()` | Ajuste param√©trico basado en win rate reciente |

---

### üõ°Ô∏è Safety Governor (Milestone 6.2)
Sistema anti-overfitting integrado en `EdgeTuner`. Aplica dos restricciones secuenciales:

| Regla | Valor | Descripci√≥n |
|---|---|---|
| `GOVERNANCE_MIN_WEIGHT` | `0.10` (10%) | Floor: ning√∫n peso puede bajar de aqu√≠ |
| `GOVERNANCE_MAX_WEIGHT` | `0.50` (50%) | Ceiling: ning√∫n peso puede subir de aqu√≠ |
| `GOVERNANCE_MAX_SMOOTHING` | `0.02` (2%) | Max cambio por evento de aprendizaje |

Cuando el Governor interviene, el campo `action_taken` del evento en `edge_learning` incluye el tag `[SAFETY_GOVERNOR]`, lo que activa el badge **‚ö° Governor Active** en el panel `NeuralHistoryPanel` de la UI.

**Tests**: `tests/test_governance_limits.py` ‚Äî **16/16 ‚úÖ**
