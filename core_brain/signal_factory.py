"""
Signal Factory - Motor de Generaci√≥n de Se√±ales para Aethelgard
==============================================================

Refactorizado a Patr√≥n Strategy (Fase 2.2).
Act√∫a como orquestador que delega la l√≥gica de an√°lisis a estrategias espec√≠ficas
(e.g., OliverVelezStrategy) y gestiona la persistencia y notificaci√≥n centralizada.

FASE 2.5: Multi-Timeframe Confluence Integration
Signals are reinforced or penalized based on alignment across timeframes.
EDGE learning optimizes confluence weights automatically.
"""
import logging
import asyncio
import json
from typing import Dict, List, Optional
from collections import defaultdict

import pandas as pd

from models.signal import (
    Signal, MarketRegime, MembershipTier, ConnectorType
)
from data_vault.storage import StorageManager
from core_brain.notificator import get_notifier, TelegramNotifier
from core_brain.module_manager import MembershipLevel
from core_brain.confluence import MultiTimeframeConfluenceAnalyzer

# Import strategies
from core_brain.strategies.base_strategy import BaseStrategy
from core_brain.strategies.oliver_velez import OliverVelezStrategy

logger = logging.getLogger(__name__)

class SignalFactory:
    """
    Orquestador de estrategias.
    
    Responsabilidades:
    1. Administrar lista de estrategias activas.
    2. Recibir datos del Scanner.
    3. Delegar an√°lisis a cada estrategia.
    4. Persistir se√±ales generadas.
    5. Notificar se√±ales generadas.
    """

    def __init__(
        self,
        storage_manager: StorageManager,
        config_path: str = "config/dynamic_params.json",
        strategy_id: str = "deprecated", # Mantenido por compatibilidad
        mt5_connector: Optional[Any] = None,
    ):
        """
        Inicializa la SignalFactory.

        Args:
            storage_manager: Instancia del gestor de persistencia.
            config_path: Ruta a dynamic_params.json.
            strategy_id: Deprecado. Las estrategias se cargan internamente.
            mt5_connector: Opcional MT5 connector para reconciliaci√≥n.
        """
        self.storage_manager = storage_manager
        self.notifier: Optional[TelegramNotifier] = get_notifier()
        self.config_path = config_path
        self.mt5_connector = mt5_connector
        
        # Cargar par√°metros generales
        self.config_data = self._load_parameters()
        
        # Inicializar estrategias
        self.strategies: List[BaseStrategy] = []
        self._register_default_strategies()
        
        # FASE 2.5: Initialize Multi-Timeframe Confluence Analyzer
        confluence_config = self.config_data.get("confluence", {})
        confluence_enabled = confluence_config.get("enabled", True)
        self.confluence_analyzer = MultiTimeframeConfluenceAnalyzer(
            config_path=config_path,
            enabled=confluence_enabled
        )
        
        if not self.notifier or not self.notifier.is_configured():
            logger.warning("Notificador de Telegram no est√° configurado. No se enviar√°n alertas.")

        logger.info(
            f"SignalFactory initialized with {len(self.strategies)} strategies. "
            f"Confluence enabled: {confluence_enabled}"
        )

    def set_mt5_connector(self, mt5_connector: Any) -> None:
        """Set MT5 connector for reconciliation (optional)."""
        self.mt5_connector = mt5_connector
        if mt5_connector:
            logger.info("MT5 connector set for SignalFactory reconciliation")
        else:
            logger.debug("MT5 connector cleared from SignalFactory")

    def _load_parameters(self) -> Dict:
        """Carga par√°metros desde dynamic_params.json"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            logger.info(f"Loaded configuration from {self.config_path}")
            return config
        except FileNotFoundError:
            logger.warning(f"Config not found: {self.config_path}. Using defaults.")
            return {}
        except Exception as e:
            logger.error(f"Error loading config: {e}. Using empty config.")
            return {}

    def _register_default_strategies(self) -> None:
        """Registra las estrategias por defecto."""
        # En el futuro, esto podr√≠a ser din√°mico o v√≠a plugin
        try:
            ov_strategy = OliverVelezStrategy(self.config_data)
            self.strategies.append(ov_strategy)
            logger.info(f"Strategy registered: {ov_strategy.strategy_id}")
        except Exception as e:
            logger.error(f"Failed to register OliverVelezStrategy: {e}", exc_info=True)

    async def generate_signal(
        self, symbol: str, df: pd.DataFrame, regime: MarketRegime, timeframe: Optional[str] = None, trace_id: Optional[str] = None
    ) -> List[Signal]:
        """
        Analiza un s√≠mbolo con TODAS las estrategias registradas.
        
        Args:
            symbol: S√≠mbolo del activo.
            df: DataFrame con datos OHLC.
            regime: R√©gimen actual del mercado.
            timeframe: Timeframe del an√°lisis (ej: "M5", "H1"). Se incluye en signal metadata.

        Returns:
            Lista de se√±ales generadas (puede estar vac√≠a).
        """
        generated_signals = []
        
        for strategy in self.strategies:
            try:
                # Delegar an√°lisis a la estrategia
                signal = await strategy.analyze(symbol, df, regime)
                
                if signal:
                    # Set timeframe in signal if provided
                    if timeframe:
                        signal.timeframe = timeframe
                    
                    # Set trace_id for pipeline tracking
                    if trace_id:
                        signal.trace_id = trace_id
                    
                    # Validar que no sea duplicado antes de procesar
                    if self._is_duplicate_signal(signal):
                        logger.info(
                            f"[{symbol}] Se√±al {signal.signal_type} descartada: "
                            f"ya existe posici√≥n abierta o se√±al reciente"
                        )
                        continue
                    
                    # Procesar se√±al v√°lida
                    await self._process_valid_signal(signal)
                    generated_signals.append(signal)
            
            except Exception as e:
                logger.error(
                    f"Error running strategy {strategy.strategy_id} on {symbol}: {e}", 
                    exc_info=True
                )

        return generated_signals

    def _is_duplicate_signal(self, signal: Signal) -> bool:
        """
        Verifica si la se√±al es un duplicado.
        
        Criterios de deduplicaci√≥n (clave √∫nica: symbol + signal_type + timeframe):
        - Ya existe una posici√≥n abierta para el s√≠mbolo
        - Ya existe una se√±al reciente para el mismo (symbol, signal_type, timeframe)
        
        Esto permite se√±ales del MISMO instrumento en DIFERENTES timeframes.
        Ejemplo: EURUSD BUY en M5 (scalping) y EURUSD BUY en H4 (swing) son v√°lidas simult√°neamente.
        
        Args:
            signal: Se√±al a validar
        
        Returns:
            True si es duplicado, False si es v√°lida
        """
        signal_type_str = signal.signal_type.value if hasattr(signal.signal_type, 'value') else str(signal.signal_type)
        
        # Verificar posici√≥n abierta (filtrar por symbol + timeframe)
        if self.storage_manager.has_open_position(signal.symbol, signal.timeframe):
            # Reconcilia directamente con MT5 reality
            if self.mt5_connector:
                logger.debug(f"üîç Reconciling position for {signal.symbol} with MT5")
                # Get open signal ID
                open_signal_id = self.storage_manager.get_open_signal_id(signal.symbol)
                if open_signal_id:
                    # Check MT5 positions
                    real_positions = self.mt5_connector.get_open_positions()
                    if real_positions is not None:
                        real_symbols = {pos.get('symbol') for pos in real_positions}
                        if signal.symbol not in real_symbols:
                            # Ghost position detected - clear it
                            self.storage_manager._clear_ghost_position_inline(signal.symbol)
                            logger.info(f"üßπ Cleared ghost position for {signal.symbol} (ID: {open_signal_id})")
                            # EDGE Learning
                            self.storage_manager.save_edge_learning(
                                detection=f"Discrepancia DB vs MT5: {signal.symbol} tiene posici√≥n en DB pero no en MT5",
                                action_taken="Limpieza de registros fantasma",
                                learning="El delay de cierre en MT5 es de 200ms, ajustar timeout",
                                details=f"Signal ID: {open_signal_id}"
                            )
                        else:
                            # Position exists in MT5, keep as is
                            pass
                    else:
                        logger.warning("Failed to get MT5 positions for reconciliation")
                # Check again after reconciliation
                if self.storage_manager.has_open_position(signal.symbol):
                    # Volcado por excepci√≥n t√©cnica: posici√≥n abierta
                    score = signal.metadata.get('score', 0)
                    lot_size = signal.volume
                    risk_usd = abs(signal.entry_price - signal.stop_loss) * lot_size * 100000
                    ghost_id = self.storage_manager.get_open_signal_id(signal.symbol)
                    dump = {
                        "Raz√≥n": "Posici√≥n abierta existente",
                        "Score": score,
                        "LotSize": lot_size,
                        "Riesgo_$": round(risk_usd, 2),
                        "ID_Posicion_Existente": ghost_id or "UNKNOWN"
                    }
                    logger.info(f"üß† VOLCADO EXCEPCI√ìN: Se√±al descartada por posici√≥n abierta: {dump}")
                    return True
            else:
                # Sin MT5, asumir existe
                score = signal.metadata.get('score', 0)
                lot_size = signal.volume
                risk_usd = abs(signal.entry_price - signal.stop_loss) * lot_size * 100000
                dump = {
                    "Raz√≥n": "Posici√≥n abierta (sin MT5 para verificar)",
                    "Score": score,
                    "LotSize": lot_size,
                    "Riesgo_$": round(risk_usd, 2),
                    "ID_Posicion_Existente": "UNKNOWN"
                }
                logger.info(f"üß† VOLCADO EXCEPCI√ìN: Se√±al descartada por posici√≥n abierta: {dump}")
                return True
        
        # DUPLICATE VALIDATION REMOVED: Now handled by Executor at execution time
        # Executor validates against EXECUTED positions before submitting to MT5
        # This allows SignalFactory to generate signals freely (architectural fix)
        
        return False

    async def _process_valid_signal(self, signal: Signal) -> None:
        """Maneja persistencia y notificaci√≥n de una se√±al v√°lida."""
        try:
            # 0. Normalize symbol for MT5 (provider ‚Üí MT5 format) BEFORE saving to DB
            if signal.connector_type == ConnectorType.METATRADER5:
                try:
                    from connectors.mt5_connector import MT5Connector
                    normalized = MT5Connector.normalize_symbol(signal.symbol)
                    if normalized != signal.symbol:
                        logger.debug(f"[FACTORY NORM] {signal.symbol} ‚Üí {normalized}")
                        if hasattr(signal, 'metadata') and isinstance(signal.metadata, dict):
                            signal.metadata.setdefault("symbol_normalized_from", signal.symbol)
                        signal.symbol = normalized
                except Exception as e:
                    logger.warning(f"Symbol normalization failed in SignalFactory: {e}")
            
            # 1. Persistencia (guarda con status='PENDING' por defecto)
            signal_id = self.storage_manager.save_signal(signal)
            
            # CLAVE: Asignar ID al objeto Signal para que Executor lo use (evita duplicados)
            signal.metadata['signal_id'] = signal_id
            
            logger.info(
                f"SE√ëAL GENERADA [ID: {signal_id}] -> {signal.symbol} "
                f"{signal.signal_type} @ {signal.entry_price:.5f} | "
                f"Strategy: {signal.metadata.get('strategy_id')} | "
                f"Score: {signal.metadata.get('score', 0):.1f}"
            )
            
            # 2. Notificaci√≥n
            # TODO: Hacer esto m√°s gen√©rico en el futuro
            if self.notifier:
                # Determinar membership level basado en signal metadata
                membership_tier_str = signal.metadata.get("membership_tier", "FREE")
                try:
                    membership_tier = MembershipTier(membership_tier_str)
                except ValueError:
                    membership_tier = MembershipTier.FREE
                
                # Mapear MembershipTier a MembershipLevel (si son distintos enums)
                # Asumimos que MembershipLevel tiene PREMIUM y BASIC
                notif_membership = MembershipLevel.BASIC
                if membership_tier in [MembershipTier.PREMIUM, MembershipTier.ELITE]:
                    notif_membership = MembershipLevel.PREMIUM

                if membership_tier in [MembershipTier.PREMIUM, MembershipTier.ELITE]:
                    logger.debug(f"[{signal.symbol}] Disparando notificaci√≥n PREMIUM")
                    
                    if signal.metadata.get("strategy_id") == "oliver_velez_swing_v2":
                        asyncio.create_task(
                            self.notifier.notify_oliver_velez_signal(
                                signal, membership=notif_membership
                            )
                        )
                    else:
                        # Fallback para otras estrategias (provisional)
                        # asyncio.create_task(self.notifier.notify_generic_signal(signal))
                        pass

        except Exception as e:
            logger.error(f"Error processing valid signal for {signal.symbol}: {e}")

    async def generate_signals_batch(
        self, scan_results: Dict[str, Dict], trace_id: Optional[str] = None
    ) -> List[Signal]:
        """
        Procesa un lote de resultados del ScannerEngine y genera se√±ales.
        
        FASE 2.5: Aplica confluencia multi-timeframe para reforzar/penalizar se√±ales.

        Args:
            scan_results: Dict con "symbol|timeframe" -> {"regime": MarketRegime, "df": DataFrame, "symbol": str, "timeframe": str}

        Returns:
            Lista plana de todas las se√±ales generadas (con confluencia aplicada).
        """
        try:
            logger.info(f"DEBUG: generate_signals_batch called with {len(scan_results)} items")
            tasks = []
            
            if not self.strategies:
                logger.error("DEBUG: No strategies registered in SignalFactory!")
                return []
            logger.info(f"DEBUG: Strategies available: {[s.strategy_id for s in self.strategies]}")

            for key, data in scan_results.items():
                regime = data.get("regime")
                df = data.get("df")
                symbol = data.get("symbol")  # Extraer symbol del dict
                timeframe = data.get("timeframe")  # Extraer timeframe del dict
                
                if regime and df is not None and symbol:
                    # Pass both symbol and timeframe to strategies
                    # Strategies will use timeframe for signal metadata
                    tasks.append(self.generate_signal(symbol, df, regime, timeframe, trace_id))

            if not tasks:
                logger.warning("DEBUG: No tasks created (missing data in scan_results?)")
                return []

            # results es una lista de listas de se√±ales: [[s1, s2], [], [s3]]
            results = await asyncio.gather(*tasks)
            
            # Aplanar lista
            all_signals = []
            for batch in results:
                all_signals.extend(batch)

            logger.info(f"DEBUG: Raw signals generated: {len(all_signals)}")

            # FASE 2.5: Apply Multi-Timeframe Confluence
            # if all_signals and self.confluence_analyzer.enabled:
            #     all_signals = self._apply_confluence(all_signals, scan_results)

            if all_signals:
                logger.info(
                    f"Batch completado. {len(all_signals)} se√±ales generadas de "
                    f"{len(scan_results)} instrumentos analizados (multi-timeframe)."
                )

            return all_signals
            
        except Exception as e:
            logger.error(f"CRITICAL ERROR in generate_signals_batch: {e}", exc_info=True)
            return []
    
    def _apply_confluence(
        self, 
        signals: List[Signal], 
        scan_results: Dict[str, Dict]
    ) -> List[Signal]:
        """
        Apply multi-timeframe confluence to signals.
        
        Groups signals by symbol, extracts regime from all timeframes,
        and applies confluence analysis.
        
        Args:
            signals: List of generated signals
            scan_results: Original scan data (needed for regime context)
        
        Returns:
            Signals with adjusted confidence based on confluence
        """
        # Group scan results by symbol to get regime context
        symbol_regimes = defaultdict(dict)
        for key, data in scan_results.items():
            symbol = data.get("symbol")
            timeframe = data.get("timeframe")
            regime = data.get("regime")
            
            if symbol and timeframe and regime:
                symbol_regimes[symbol][timeframe] = regime
        
        # Apply confluence to each signal
        adjusted_signals = []
        for signal in signals:
            # Get timeframe regimes for this symbol
            timeframe_regimes = symbol_regimes.get(signal.symbol, {})
            
            # Remove primary signal's timeframe (don't compare M5 to M5)
            primary_timeframe = signal.timeframe
            higher_timeframes = {
                tf: regime 
                for tf, regime in timeframe_regimes.items() 
                if tf != primary_timeframe
            }
            
            if higher_timeframes:
                # Apply confluence
                adjusted_signal = self.confluence_analyzer.analyze_confluence(
                    signal, higher_timeframes
                )
                adjusted_signals.append(adjusted_signal)
            else:
                # No higher timeframes available, keep signal as-is
                adjusted_signals.append(signal)
        
        return adjusted_signals

    async def process_scan_results(self, scan_results: Dict[str, MarketRegime]) -> List[Signal]:
        """
        M√©todo de compatibilidad/logging. 
        MainOrchestrator ahora usa generate_signals_batch directamente con datos.
        """
        logger.debug("process_scan_results called (metadata only)")
        return []

    def filter_by_membership(
        self, signals: List[Signal], user_tier: MembershipTier
    ) -> List[Signal]:
        """Filtra se√±ales seg√∫n el tier de membres√≠a del usuario."""
        tier_order = {
            MembershipTier.FREE: 0,
            MembershipTier.PREMIUM: 1,
            MembershipTier.ELITE: 2
        }
        user_level = tier_order.get(user_tier, 0)

        filtered = [
            s for s in signals
            # Se asume que signal.membership_tier es un enum MembershipTier
            if tier_order.get(MembershipTier(s.metadata.get("membership_tier", "FREE")), 0) <= user_level
        ]
        return filtered
